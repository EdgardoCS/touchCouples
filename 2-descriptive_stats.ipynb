{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T14:41:24.961934Z",
     "start_time": "2026-02-16T14:41:24.954113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "a595510f0aaf52a7",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T14:41:25.047457Z",
     "start_time": "2026-02-16T14:41:24.974185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('source/FReDA3.csv')\n",
    "df2 = pd.read_csv('source/FReDA4.csv')"
   ],
   "id": "92d5ed993985fc6a",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T14:41:25.060930Z",
     "start_time": "2026-02-16T14:41:25.052232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "couples_satisfied = df[df[\"Group3\"] == \"Couple Satisfaction\"].copy()\n",
    "couples_deprived = df[df[\"Group3\"] == \"Couple Deprivation\"].copy()\n",
    "couples_saturated = df[df[\"Group3\"] == \"Couple Saturation\"].copy()\n",
    "couples_mixed = df[df[\"Group3\"] == \"Couple Mixed\"].copy()"
   ],
   "id": "2eec0bd034d43b0f",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T14:41:25.091673Z",
     "start_time": "2026-02-16T14:41:25.064221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dfs = [couples_satisfied, couples_deprived, couples_saturated, couples_mixed]\n",
    "\n",
    "for df in dfs:\n",
    "\n",
    "    # 1. Identify columns (adjust names to match your exact CSV/DataFrame)\n",
    "    items = ['Frequency', 'Kiss Frequency', 'Hold Frequency', 'Hug Frequency',\n",
    "             'Desire', 'Kiss Desire', 'Hold Desire', 'Hug Desire']\n",
    "\n",
    "    # 2. Create 'Side A' (Anchor is the primary)\n",
    "    side_a = df[['Id'] + [f'Anchor {i}' for i in items] + [f'Partner {i}' for i in items]].copy()\n",
    "    side_a.columns = ['Couple_ID'] + [f'Self_{i}' for i in items] + [f'Partner_{i}' for i in items]\n",
    "\n",
    "    # 3. Create 'Side B' (Partner is the primary)\n",
    "    side_b = df[['Id'] + [f'Partner {i}' for i in items] + [f'Anchor {i}' for i in items]].copy()\n",
    "    side_b.columns = ['Couple_ID'] + [f'Self_{i}' for i in items] + [f'Partner_{i}' for i in items]\n",
    "\n",
    "    # 4. Merge\n",
    "    df_long = pd.concat([side_a, side_b], ignore_index=True)\n",
    "\n",
    "    # Select all Self and Partner columns to center\n",
    "    cols_to_center = [c for c in df_long.columns if 'Self_' in c or 'Partner_' in c]\n",
    "\n",
    "    # Calculate the mean for each couple ID\n",
    "    couple_means = df_long.groupby('Couple_ID')[cols_to_center].transform('mean')\n",
    "\n",
    "    # Center the data: (Actual Value - Couple Mean)\n",
    "    df_centered = df_long[cols_to_center] - couple_means\n",
    "\n",
    "    results = []\n",
    "    # Match Frequency items to their corresponding Desire items\n",
    "    categories = ['Frequency', 'Kiss Frequency', 'Hold Frequency', 'Hug Frequency']\n",
    "\n",
    "    for cat in categories:\n",
    "        freq_col = f'Self_{cat}'\n",
    "        # Mapping 'Frequency' to 'Desire'\n",
    "        desire_col = freq_col.replace('Frequency', 'Desire')\n",
    "\n",
    "        # Calculate Spearman Correlation on the centered data\n",
    "        r_val, p_val = stats.spearmanr(df_centered[freq_col], df_centered[desire_col])\n",
    "\n",
    "        results.append({\n",
    "            'Touch Type': cat.replace(' Frequency', '') or 'Overall',\n",
    "            'Spearman r (rm)': round(r_val, 3),\n",
    "            'p-value': '< .001' if p_val < .001 else round(p_val, 4)\n",
    "        })\n",
    "\n",
    "    # Final Table\n",
    "    table_output = pd.DataFrame(results)\n",
    "    print(table_output)"
   ],
   "id": "c3202867f0b0e3ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Touch Type  Spearman r (rm) p-value\n",
      "0  Frequency            1.000  < .001\n",
      "1       Kiss            0.991  < .001\n",
      "2       Hold            0.997  < .001\n",
      "3        Hug            0.995  < .001\n",
      "  Touch Type  Spearman r (rm) p-value\n",
      "0  Frequency            0.609  < .001\n",
      "1       Kiss            0.562  < .001\n",
      "2       Hold            0.672  < .001\n",
      "3        Hug            0.603  < .001\n",
      "  Touch Type  Spearman r (rm) p-value\n",
      "0  Frequency            0.586  < .001\n",
      "1       Kiss            0.433  < .001\n",
      "2       Hold            0.632  < .001\n",
      "3        Hug            0.650  < .001\n",
      "  Touch Type  Spearman r (rm) p-value\n",
      "0  Frequency            0.228  < .001\n",
      "1       Kiss            0.215  < .001\n",
      "2       Hold            0.330  < .001\n",
      "3        Hug            0.270  < .001\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T14:41:25.106839Z",
     "start_time": "2026-02-16T14:41:25.096597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "couples_satisfied = df2[df2[\"Group3\"] == \"Couple Satisfaction\"].copy()\n",
    "couples_deprived = df2[df2[\"Group3\"] == \"Couple Deprivation\"].copy()\n",
    "couples_saturated = df2[df2[\"Group3\"] == \"Couple Saturation\"].copy()\n",
    "couples_mixed = df2[df2[\"Group3\"] == \"Couple Mixed\"].copy()\n",
    "\n",
    "groups = ['Couple Deprivation', 'Couple Mixed', 'Couple Satisfaction', 'Couple Saturation']"
   ],
   "id": "e228ab326c55c715",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T14:41:25.115190Z",
     "start_time": "2026-02-16T14:41:25.111186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_interpretations(df):\n",
    "    baseline = 'Couple Satisfaction'\n",
    "    others = [g for g in df.index if g != baseline]\n",
    "\n",
    "    # Mapping for shorthand report\n",
    "    name_map = {\n",
    "        'Couple Deprivation': 'D',\n",
    "        'Couple Mixed': 'Mixed',\n",
    "        'Couple Saturation': 'Sat'\n",
    "    }\n",
    "\n",
    "    print(f\"{'Level':<10} | {'Comparison':<15} | {'Significance'}\")\n",
    "    print(\"-\" * 45)\n",
    "\n",
    "    for level in df.columns:\n",
    "        s_val = df.loc[baseline, level]\n",
    "\n",
    "        for other in others:\n",
    "            o_val = df.loc[other, level]\n",
    "\n",
    "            # Direction\n",
    "            symbol = \">\" if s_val > o_val else \"<\"\n",
    "\n",
    "            # Significance Check (Difference > 1.96)\n",
    "            diff = abs(s_val - o_val)\n",
    "            sig_status = \"Significant\" if diff > 1.96 else \"Not Significant\"\n",
    "\n",
    "            print(f\"{level:<10} | S {symbol} {name_map[other]:<10} | {sig_status}\")\n",
    "        print(\"-\" * 45)"
   ],
   "id": "1e49c95d44d0994c",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T14:41:25.134924Z",
     "start_time": "2026-02-16T14:41:25.115190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dv = 'Education'\n",
    "kruskal_anova = pg.kruskal(data=df2, dv=dv, between='Group3')\n",
    "n = df2[dv].count()\n",
    "k = df2[\"Group3\"].nunique()\n",
    "eta_sq_h = (kruskal_anova[\"H\"].item() - k + 1) / (n - k)\n",
    "\n",
    "print(kruskal_anova)\n",
    "print('ETA-squared', eta_sq_h)\n",
    "\n",
    "# 1. Run the Chi-square independence test\n",
    "expected, observed, stats = pg.chi2_independence(df2, x='Group3', y=dv)\n",
    "\n",
    "# 2. Calculate Standardized Residuals\n",
    "# These identify exactly which levels (0, 1, 2...) are different\n",
    "residuals = (observed - expected) / (expected**0.5)\n",
    "\n",
    "# 3. Print the residuals for the \"Satisfied\" row vs the others\n",
    "print(\"--- (Standardized Residuals) ---\")\n",
    "print(residuals.round(2))\n",
    "\n",
    "df_res = pd.DataFrame(residuals, index=groups)\n",
    "# Run the function\n",
    "generate_interpretations(df_res)\n",
    "\n",
    "# drop = True\n",
    "#\n",
    "# count_base = couples_satisfied[dv].value_counts(dropna=drop)\n",
    "# count_d = couples_deprived[dv].value_counts(dropna=drop)\n",
    "# count_s = couples_saturated[dv].value_counts(dropna=drop)\n",
    "# count_m = couples_mixed[dv].value_counts(dropna=drop)\n",
    "#\n",
    "# summ = pd.DataFrame({\n",
    "#     'Satisfied': count_base,\n",
    "#     'Deprived': count_d,\n",
    "#     'Saturated': count_s,\n",
    "#     'Mixed': count_m,\n",
    "# })\n",
    "#\n",
    "# summ_cond = [\"Deprived\", \"Saturated\", \"Mixed\"]\n",
    "# for cond in summ_cond:\n",
    "#     print('Pairwise ---', cond)\n",
    "#     contingency = summ.filter(items=['Satisfied', cond])\n",
    "#     N = contingency.to_numpy().sum()\n",
    "#     res = chi2_contingency(contingency)\n",
    "#     chi_stat = res[0]\n",
    "#     print(f\"Dof:{res.dof}, Chi-square: {res.statistic}, p-value: {res.pvalue}\")\n",
    "#\n",
    "#     # Calculate Cramer's V\n",
    "#     r, k = contingency.shape\n",
    "#     result = np.sqrt(chi_stat / (N * (min(r-1, k-1))))\n",
    "#\n",
    "#     print(f\"Cramer's V: {result}\")"
   ],
   "id": "5be16c0d801be305",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Source  ddof1          H         p-unc\n",
      "Kruskal  Group3      3  45.665449  6.680727e-10\n",
      "ETA-squared 0.00338802896202501\n",
      "--- (Standardized Residuals) ---\n",
      "Education             0.0   1.0   2.0   3.0   4.0   6.0   7.0   8.0\n",
      "Group3                                                             \n",
      "Couple Deprivation  -3.97  0.74 -0.82 -0.56 -0.01  0.47  0.65  1.28\n",
      "Couple Mixed        -1.25 -0.42  2.20  1.31  1.33 -1.79 -0.29 -0.22\n",
      "Couple Satisfaction  5.22 -1.73 -0.96 -1.53 -0.16  0.94 -0.10 -0.50\n",
      "Couple Saturation    2.73  1.84  2.90  4.16 -0.87 -2.03 -1.70 -2.99\n",
      "Level      | Comparison      | Significance\n",
      "---------------------------------------------\n",
      "0.0        | S > D          | Significant\n",
      "0.0        | S > Mixed      | Significant\n",
      "0.0        | S > Sat        | Significant\n",
      "---------------------------------------------\n",
      "1.0        | S < D          | Significant\n",
      "1.0        | S < Mixed      | Not Significant\n",
      "1.0        | S < Sat        | Significant\n",
      "---------------------------------------------\n",
      "2.0        | S < D          | Not Significant\n",
      "2.0        | S < Mixed      | Significant\n",
      "2.0        | S < Sat        | Significant\n",
      "---------------------------------------------\n",
      "3.0        | S < D          | Not Significant\n",
      "3.0        | S < Mixed      | Significant\n",
      "3.0        | S < Sat        | Significant\n",
      "---------------------------------------------\n",
      "4.0        | S < D          | Not Significant\n",
      "4.0        | S < Mixed      | Not Significant\n",
      "4.0        | S > Sat        | Not Significant\n",
      "---------------------------------------------\n",
      "6.0        | S > D          | Not Significant\n",
      "6.0        | S > Mixed      | Significant\n",
      "6.0        | S > Sat        | Significant\n",
      "---------------------------------------------\n",
      "7.0        | S < D          | Not Significant\n",
      "7.0        | S > Mixed      | Not Significant\n",
      "7.0        | S > Sat        | Not Significant\n",
      "---------------------------------------------\n",
      "8.0        | S < D          | Not Significant\n",
      "8.0        | S < Mixed      | Not Significant\n",
      "8.0        | S > Sat        | Significant\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T14:41:25.154513Z",
     "start_time": "2026-02-16T14:41:25.140525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dv = 'Work Status'\n",
    "kruskal_anova = pg.kruskal(data=df2, dv=dv, between='Group3')\n",
    "n = df2[dv].count()\n",
    "k = df2[\"Group3\"].nunique()\n",
    "eta_sq_h = (kruskal_anova[\"H\"].item() - k + 1) / (n - k)\n",
    "\n",
    "print(kruskal_anova)\n",
    "print('ETA-squared', eta_sq_h)\n",
    "\n",
    "# 1. Run the Chi-square independence test\n",
    "expected, observed, stats = pg.chi2_independence(df2, x='Group3', y=dv)\n",
    "\n",
    "# 2. Calculate Standardized Residuals\n",
    "# These identify exactly which levels (0, 1, 2...) are different\n",
    "residuals = (observed - expected) / (expected**0.5)\n",
    "\n",
    "# 3. Print the residuals for the \"Satisfied\" row vs the others\n",
    "print(\"--- (Standardized Residuals) ---\")\n",
    "print(residuals.round(2))\n",
    "\n",
    "df_res = pd.DataFrame(residuals, index=groups)\n",
    "generate_interpretations(df_res)"
   ],
   "id": "f4cdf1473afdcf62",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Source  ddof1           H         p-unc\n",
      "Kruskal  Group3      3  135.454842  3.608807e-29\n",
      "ETA-squared 0.009853071605688202\n",
      "--- (Standardized Residuals) ---\n",
      "Work Status           0.0   1.0   2.0\n",
      "Group3                               \n",
      "Couple Deprivation   3.60  4.66 -3.87\n",
      "Couple Mixed         0.25 -0.43  0.13\n",
      "Couple Satisfaction -5.21 -5.22  4.80\n",
      "Couple Saturation   -0.42 -3.29  1.90\n",
      "Level      | Comparison      | Significance\n",
      "---------------------------------------------\n",
      "0.0        | S < D          | Significant\n",
      "0.0        | S < Mixed      | Significant\n",
      "0.0        | S < Sat        | Significant\n",
      "---------------------------------------------\n",
      "1.0        | S < D          | Significant\n",
      "1.0        | S < Mixed      | Significant\n",
      "1.0        | S < Sat        | Not Significant\n",
      "---------------------------------------------\n",
      "2.0        | S > D          | Significant\n",
      "2.0        | S > Mixed      | Significant\n",
      "2.0        | S > Sat        | Significant\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T14:41:25.176468Z",
     "start_time": "2026-02-16T14:41:25.162021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dv = 'Urbanization'\n",
    "kruskal_anova = pg.kruskal(data=df2, dv=dv, between='Group3')\n",
    "n = df2[dv].count()\n",
    "k = df2[\"Group3\"].nunique()\n",
    "eta_sq_h = (kruskal_anova[\"H\"].item() - k + 1) / (n - k)\n",
    "\n",
    "print(kruskal_anova)\n",
    "print('ETA-squared', eta_sq_h)\n",
    "\n",
    "# 1. Run the Chi-square independence test\n",
    "expected, observed, stats = pg.chi2_independence(df2, x='Group3', y=dv)\n",
    "\n",
    "# 2. Calculate Standardized Residuals\n",
    "# These identify exactly which levels (0, 1, 2...) are different\n",
    "residuals = (observed - expected) / (expected ** 0.5)\n",
    "\n",
    "# 3. Print the residuals for the \"Satisfied\" row vs the others\n",
    "print(\"--- \", dv, \"(Standardized Residuals) ---\")\n",
    "print(residuals.round(2))\n",
    "\n",
    "df_res = pd.DataFrame(residuals, index=groups)\n",
    "print(\"--- \", dv, \"(Interpretation) ---\")\n",
    "generate_interpretations(df_res)"
   ],
   "id": "8173529512015eb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Source  ddof1         H     p-unc\n",
      "Kruskal  Group3      3  25.16126  0.000014\n",
      "ETA-squared 0.001675709651394591\n",
      "---  Urbanization (Standardized Residuals) ---\n",
      "Urbanization          0.0   1.0   2.0\n",
      "Group3                               \n",
      "Couple Deprivation   1.27  1.22 -2.17\n",
      "Couple Mixed        -1.75 -1.37  2.66\n",
      "Couple Satisfaction -0.99 -0.52  1.24\n",
      "Couple Saturation   -0.36 -1.62  1.93\n",
      "---  Urbanization (Interpretation) ---\n",
      "Level      | Comparison      | Significance\n",
      "---------------------------------------------\n",
      "0.0        | S < D          | Significant\n",
      "0.0        | S > Mixed      | Not Significant\n",
      "0.0        | S < Sat        | Not Significant\n",
      "---------------------------------------------\n",
      "1.0        | S < D          | Not Significant\n",
      "1.0        | S > Mixed      | Not Significant\n",
      "1.0        | S > Sat        | Not Significant\n",
      "---------------------------------------------\n",
      "2.0        | S > D          | Significant\n",
      "2.0        | S < Mixed      | Not Significant\n",
      "2.0        | S < Sat        | Not Significant\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T14:41:25.196752Z",
     "start_time": "2026-02-16T14:41:25.181032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dv = 'Kids'\n",
    "kruskal_anova = pg.kruskal(data=df2, dv=dv, between='Group3')\n",
    "n = df2[dv].count()\n",
    "k = df2[\"Group3\"].nunique()\n",
    "eta_sq_h = (kruskal_anova[\"H\"].item() - k + 1) / (n - k)\n",
    "\n",
    "print(kruskal_anova)\n",
    "print('ETA-squared', eta_sq_h)\n",
    "\n",
    "# 1. Run the Chi-square independence test\n",
    "expected, observed, stats = pg.chi2_independence(df2, x='Group3', y=dv)\n",
    "\n",
    "# 2. Calculate Standardized Residuals\n",
    "# These identify exactly which levels (0, 1, 2...) are different\n",
    "residuals = (observed - expected) / (expected ** 0.5)\n",
    "\n",
    "# 3. Print the residuals for the \"Satisfied\" row vs the others\n",
    "print(\"--- \", dv, \"(Standardized Residuals) ---\")\n",
    "print(residuals.round(2))\n",
    "\n",
    "df_res = pd.DataFrame(residuals, index=groups)\n",
    "print(\"--- \", dv, \"(Interpretation) ---\")\n",
    "generate_interpretations(df_res)"
   ],
   "id": "902e2c513726f0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Source  ddof1           H          p-unc\n",
      "Kruskal  Group3      3  509.248086  4.725396e-110\n",
      "ETA-squared 0.03726248242713801\n",
      "---  Kids (Standardized Residuals) ---\n",
      "Kids                   0.0   1.0   2.0   3.0\n",
      "Group3                                      \n",
      "Couple Deprivation  -11.52  5.30  7.25  3.62\n",
      "Couple Mixed          0.66  1.38 -0.73 -2.23\n",
      "Couple Satisfaction  13.62 -7.52 -7.90 -3.53\n",
      "Couple Saturation     6.94 -1.94 -5.60 -1.98\n",
      "---  Kids (Interpretation) ---\n",
      "Level      | Comparison      | Significance\n",
      "---------------------------------------------\n",
      "0.0        | S > D          | Significant\n",
      "0.0        | S > Mixed      | Significant\n",
      "0.0        | S > Sat        | Significant\n",
      "---------------------------------------------\n",
      "1.0        | S < D          | Significant\n",
      "1.0        | S < Mixed      | Significant\n",
      "1.0        | S < Sat        | Significant\n",
      "---------------------------------------------\n",
      "2.0        | S < D          | Significant\n",
      "2.0        | S < Mixed      | Significant\n",
      "2.0        | S < Sat        | Significant\n",
      "---------------------------------------------\n",
      "3.0        | S < D          | Significant\n",
      "3.0        | S < Mixed      | Not Significant\n",
      "3.0        | S < Sat        | Not Significant\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T14:41:25.208809Z",
     "start_time": "2026-02-16T14:41:25.196752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "count_base = couples_satisfied['Region'].value_counts(dropna=False)\n",
    "count_d = couples_deprived['Region'].value_counts(dropna=False)\n",
    "count_s = couples_saturated['Region'].value_counts(dropna=False)\n",
    "count_m = couples_mixed['Region'].value_counts(dropna=False)\n",
    "\n",
    "contingency = pd.DataFrame({\n",
    "    'Satisfied': count_base,\n",
    "    'Deprived': count_d,\n",
    "    # 'Saturated': count_s,\n",
    "    # 'Mixed': count_m,\n",
    "})\n",
    "\n",
    "print(contingency)\n",
    "res = chi2_contingency(contingency)\n",
    "chi_stat = res[0]\n",
    "\n",
    "# Performing Cramer's V calculation\n",
    "# Size of the sample\n",
    "N = contingency.to_numpy().sum()\n",
    "# Minimum dimension\n",
    "minimum_dimension = (min(contingency.shape)-1)\n",
    "\n",
    "# Calculate Cramer's V\n",
    "r, k = contingency.shape\n",
    "result = np.sqrt(chi_stat / (N * (min(r-1, k-1))))\n",
    "\n",
    "chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "(expected < 5).sum()\n",
    "n_violations = (expected < 5).sum()\n",
    "total_cells = expected.size\n",
    "\n",
    "print(f\"Cells with expected count < 5: {n_violations}/{total_cells}\")\n",
    "print(f\"Percentage: {100 * n_violations / total_cells:.1f}%\")\n",
    "print(f\"Cramer's V: {result}\")\n",
    "print(f\"Dof:{res.dof}, Chi-square: {res.statistic}, p-value: {res.pvalue}\")"
   ],
   "id": "1d7983c5033a92c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Satisfied  Deprived\n",
      "Region                     \n",
      "1.0          3210      6858\n",
      "0.0           533      1273\n",
      "NaN            99       211\n",
      "Cells with expected count < 5: 0/6\n",
      "Percentage: 0.0%\n",
      "Cramer's V: 0.01814015824374786\n",
      "Dof:2, Chi-square: 4.009332116062472, p-value: 0.13470527192907278\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T14:50:46.545133Z",
     "start_time": "2026-02-16T14:50:46.527831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dv = 'Married'\n",
    "kruskal_anova = pg.kruskal(data=df2, dv=dv, between='Group3')\n",
    "n = df2[dv].count()\n",
    "k = df2[\"Group3\"].nunique()\n",
    "eta_sq_h = (kruskal_anova[\"H\"].item() - k + 1) / (n - k)\n",
    "\n",
    "print(kruskal_anova)\n",
    "print('ETA-squared', eta_sq_h)\n",
    "\n",
    "# 1. Run the Chi-square independence test\n",
    "expected, observed, stats = pg.chi2_independence(df2, x='Group3', y=dv)\n",
    "\n",
    "# 2. Calculate Standardized Residuals\n",
    "# These identify exactly which levels (0, 1, 2...) are different\n",
    "residuals = (observed - expected) / (expected ** 0.5)\n",
    "\n",
    "# 3. Print the residuals for the \"Satisfied\" row vs the others\n",
    "print(\"--- \", dv, \"(Standardized Residuals) ---\")\n",
    "print(residuals.round(2))\n",
    "\n",
    "df_res = pd.DataFrame(residuals, index=groups)\n",
    "print(\"--- \", dv, \"(Interpretation) ---\")\n",
    "generate_interpretations(df_res)"
   ],
   "id": "da8ec0e1d5556dbe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Source  ddof1           H         p-unc\n",
      "Kruskal  Group3      3  187.920791  1.716877e-40\n",
      "ETA-squared 0.013603118338376687\n",
      "---  Married (Standardized Residuals) ---\n",
      "Married               0.0   1.0\n",
      "Group3                         \n",
      "Couple Deprivation  -6.61  4.90\n",
      "Couple Mixed         0.82 -0.61\n",
      "Couple Satisfaction  7.12 -5.28\n",
      "Couple Saturation    5.12 -3.79\n",
      "---  Married (Interpretation) ---\n",
      "Level      | Comparison      | Significance\n",
      "---------------------------------------------\n",
      "0.0        | S > D          | Significant\n",
      "0.0        | S > Mixed      | Significant\n",
      "0.0        | S > Sat        | Significant\n",
      "---------------------------------------------\n",
      "1.0        | S < D          | Significant\n",
      "1.0        | S < Mixed      | Significant\n",
      "1.0        | S < Sat        | Not Significant\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T14:52:32.669478Z",
     "start_time": "2026-02-16T14:52:32.655221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dv = 'Cohabitation'\n",
    "kruskal_anova = pg.kruskal(data=df2, dv=dv, between='Group3')\n",
    "n = df2[dv].count()\n",
    "k = df2[\"Group3\"].nunique()\n",
    "eta_sq_h = (kruskal_anova[\"H\"].item() - k + 1) / (n - k)\n",
    "\n",
    "print(kruskal_anova)\n",
    "print('ETA-squared', eta_sq_h)\n",
    "\n",
    "# 1. Run the Chi-square independence test\n",
    "expected, observed, stats = pg.chi2_independence(df2, x='Group3', y=dv)\n",
    "\n",
    "# 2. Calculate Standardized Residuals\n",
    "# These identify exactly which levels (0, 1, 2...) are different\n",
    "residuals = (observed - expected) / (expected ** 0.5)\n",
    "\n",
    "# 3. Print the residuals for the \"Satisfied\" row vs the others\n",
    "print(\"--- \", dv, \"(Standardized Residuals) ---\")\n",
    "print(residuals.round(2))\n",
    "\n",
    "df_res = pd.DataFrame(residuals, index=groups)\n",
    "print(\"--- \", dv, \"(Interpretation) ---\")\n",
    "generate_interpretations(df_res)"
   ],
   "id": "3b29b02bfff420d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Source  ddof1          H         p-unc\n",
      "Kruskal  Group3      3  51.342131  4.136180e-11\n",
      "ETA-squared 0.003555614214657242\n",
      "---  Cohabitation (Standardized Residuals) ---\n",
      "Cohabitation            0     1\n",
      "Group3                         \n",
      "Couple Deprivation  -4.17  1.26\n",
      "Couple Mixed         0.62 -0.19\n",
      "Couple Satisfaction  4.75 -1.44\n",
      "Couple Saturation    2.58 -0.78\n",
      "---  Cohabitation (Interpretation) ---\n",
      "Level      | Comparison      | Significance\n",
      "---------------------------------------------\n",
      "0          | S > D          | Significant\n",
      "0          | S > Mixed      | Significant\n",
      "0          | S > Sat        | Significant\n",
      "---------------------------------------------\n",
      "1          | S < D          | Significant\n",
      "1          | S < Mixed      | Not Significant\n",
      "1          | S < Sat        | Not Significant\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T14:41:25.257746Z",
     "start_time": "2026-02-16T14:41:25.252045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "drop = True\n",
    "count_base = couples_satisfied['Sex'].value_counts(dropna=drop)\n",
    "count_d = couples_deprived['Sex'].value_counts(dropna=drop)\n",
    "count_s = couples_saturated['Sex'].value_counts(dropna=drop)\n",
    "count_m = couples_mixed['Sex'].value_counts(dropna=drop)\n",
    "\n",
    "contingency = pd.DataFrame({\n",
    "    'Satisfied': count_base,\n",
    "    # 'Deprived': count_d,\n",
    "    # 'Saturated': count_s,\n",
    "    'Mixed': count_m,\n",
    "})\n",
    "\n",
    "print(contingency)\n",
    "res = chi2_contingency(contingency)\n",
    "chi_stat = res[0]\n",
    "\n",
    "# Performing Cramer's V calculation\n",
    "# Size of the sample\n",
    "N = contingency.to_numpy().sum()\n",
    "# Minimum dimension\n",
    "minimum_dimension = (min(contingency.shape)-1)\n",
    "\n",
    "# Calculate Cramer's V\n",
    "r, k = contingency.shape\n",
    "result = np.sqrt(chi_stat / (N * (min(r-1, k-1))))\n",
    "\n",
    "chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "(expected < 5).sum()\n",
    "n_violations = (expected < 5).sum()\n",
    "total_cells = expected.size\n",
    "\n",
    "print(f\"Cells with expected count < 5: {n_violations}/{total_cells}\")\n",
    "print(f\"Percentage: {100 * n_violations / total_cells:.1f}%\")\n",
    "print(f\"Cramer's V: {result}\")\n",
    "print(f\"Dof:{res.dof}, Chi-square: {res.statistic}, p-value: {res.pvalue}\")"
   ],
   "id": "878a69158a268fad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Satisfied  Mixed\n",
      "Sex                  \n",
      "0.0       1916    331\n",
      "1.0       1918    328\n",
      "Cells with expected count < 5: 0/4\n",
      "Percentage: 0.0%\n",
      "Cramer's V: 0.0011659593118967008\n",
      "Dof:1, Chi-square: 0.006108058798674834, p-value: 0.9377054963235312\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T14:54:30.367836Z",
     "start_time": "2026-02-16T14:54:30.352539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "dv = 'Relationship Sex'\n",
    "kruskal_anova = pg.kruskal(data=df2, dv=dv, between='Group3')\n",
    "n = df2[dv].count()\n",
    "k = df2[\"Group3\"].nunique()\n",
    "eta_sq_h = (kruskal_anova[\"H\"].item() - k + 1) / (n - k)\n",
    "\n",
    "print(kruskal_anova)\n",
    "print('ETA-squared', eta_sq_h)\n",
    "\n",
    "# 1. Run the Chi-square independence test\n",
    "expected, observed, stats = pg.chi2_independence(df2, x='Group3', y=dv)\n",
    "\n",
    "# 2. Calculate Standardized Residuals\n",
    "# These identify exactly which levels (0, 1, 2...) are different\n",
    "residuals = (observed - expected) / (expected ** 0.5)\n",
    "\n",
    "# 3. Print the residuals for the \"Satisfied\" row vs the others\n",
    "print(\"--- \", dv, \"(Standardized Residuals) ---\")\n",
    "print(residuals.round(2))\n",
    "\n",
    "df_res = pd.DataFrame(residuals, index=groups)\n",
    "print(\"--- \", dv, \"(Interpretation) ---\")\n",
    "generate_interpretations(df_res)"
   ],
   "id": "9b19d57528963aad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Source  ddof1         H     p-unc\n",
      "Kruskal  Group3      3  3.461688  0.325765\n",
      "ETA-squared 3.395766311696073e-05\n",
      "---  Relationship Sex (Standardized Residuals) ---\n",
      "Relationship Sex        0     1\n",
      "Group3                         \n",
      "Couple Deprivation   0.12 -0.65\n",
      "Couple Mixed         0.01 -0.05\n",
      "Couple Satisfaction -0.04  0.23\n",
      "Couple Saturation   -0.32  1.69\n",
      "---  Relationship Sex (Interpretation) ---\n",
      "Level      | Comparison      | Significance\n",
      "---------------------------------------------\n",
      "0          | S < D          | Not Significant\n",
      "0          | S < Mixed      | Not Significant\n",
      "0          | S > Sat        | Not Significant\n",
      "---------------------------------------------\n",
      "1          | S > D          | Not Significant\n",
      "1          | S > Mixed      | Not Significant\n",
      "1          | S < Sat        | Not Significant\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-16T14:41:25.297252Z",
     "start_time": "2026-02-16T14:41:25.277908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "count_base = couples_satisfied['Age']\n",
    "count_d = couples_deprived['Age']\n",
    "count_s = couples_saturated['Age']\n",
    "count_m = couples_mixed['Age']\n",
    "\n",
    "rvs1 = count_base\n",
    "rvs2 = count_m\n",
    "\n",
    "t, p = stats.ttest_ind(rvs1, rvs2, equal_var=False)\n",
    "m1, sd1, n1 = rvs1.mean(), rvs1.std(ddof=1), len(rvs1)\n",
    "m2, sd2, n2 = rvs2.mean(), rvs2.std(ddof=1), len(rvs2)\n",
    "s1, s2 = sd1 ** 2, sd2 ** 2\n",
    "\n",
    "df = (s1 / n1 + s2 / n2) ** 2 / (\n",
    "        (s1 / n1) ** 2 / (n1 - 1) + (s2 / n2) ** 2 / (n2 - 1)\n",
    ")\n",
    "sd_pooled = np.sqrt((s1 + s2) / 2)\n",
    "d = (m1 - m2) / sd_pooled\n",
    "\n",
    "\n",
    "report = (\n",
    "    # f\"An independent-samples Welchâ€™s t-test showed that \"\n",
    "    # f\"Group A (M = {m1:.2f}, SD = {sd1:.2f}) scored higher than \"\n",
    "    # f\"Group B (M = {m2:.2f}, SD = {sd2:.2f}), \"\n",
    "    f\"t({df:.2f}) = {t:.2f}, p {p}, d = {d:.2f}.\"\n",
    ")\n",
    "print(report)"
   ],
   "id": "540f4e4a3ca1edfa",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'ttest_ind'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[32m~\\AppData\\Local\\Temp\\ipykernel_27012\\3583903324.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m      5\u001B[39m \n\u001B[32m      6\u001B[39m rvs1 = count_base\n\u001B[32m      7\u001B[39m rvs2 = count_m\n\u001B[32m      8\u001B[39m \n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m t, p = stats.ttest_ind(rvs1, rvs2, equal_var=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m     10\u001B[39m m1, sd1, n1 = rvs1.mean(), rvs1.std(ddof=\u001B[32m1\u001B[39m), len(rvs1)\n\u001B[32m     11\u001B[39m m2, sd2, n2 = rvs2.mean(), rvs2.std(ddof=\u001B[32m1\u001B[39m), len(rvs2)\n\u001B[32m     12\u001B[39m s1, s2 = sd1 ** \u001B[32m2\u001B[39m, sd2 ** \u001B[32m2\u001B[39m\n",
      "\u001B[32m~\\Documents\\GitHub\\touchCouples\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self, name)\u001B[39m\n\u001B[32m   6314\u001B[39m             \u001B[38;5;28;01mand\u001B[39;00m name \u001B[38;5;28;01mnot\u001B[39;00m \u001B[38;5;28;01min\u001B[39;00m self._accessors\n\u001B[32m   6315\u001B[39m             \u001B[38;5;28;01mand\u001B[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001B[32m   6316\u001B[39m         ):\n\u001B[32m   6317\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m self[name]\n\u001B[32m-> \u001B[39m\u001B[32m6318\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m object.__getattribute__(self, name)\n",
      "\u001B[31mAttributeError\u001B[39m: 'DataFrame' object has no attribute 'ttest_ind'"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rename_map = {\n",
    "    'SubGroup1': 'Satisfied',\n",
    "    'SubGroup2': 'Deprived_Me',\n",
    "    'SubGroup3': 'Deprived_Couples',\n",
    "    'SubGroup7': 'Deprived_Partner',\n",
    "    'SubGroup5': 'Saturated_Me',\n",
    "    'SubGroup6': 'Saturated_Couples',\n",
    "    'SubGroup8': 'Saturated_Partner',\n",
    "    'SubGroup4': 'Mixed_Couples',\n",
    "    'SubGroup9': 'Mixed_Couples'\n",
    "}\n",
    "\n",
    "# rename_map = {\n",
    "#     'SubGroup1': 'Satisfied',\n",
    "#     'SubGroup2': 'Deprived_One',\n",
    "#     'SubGroup3': 'Deprived_Couples',\n",
    "#     'SubGroup7': 'Deprived_One',\n",
    "#     'SubGroup5': 'Saturated_One',\n",
    "#     'SubGroup6': 'Saturated_Couples',\n",
    "#     'SubGroup8': 'Saturated_One',\n",
    "#     'SubGroup4': 'Mixed_Couples',\n",
    "#     'SubGroup9': 'Mixed_Couples'\n",
    "# }\n",
    "\n",
    "df2['Group1'] = df2['Group1'].replace(rename_map)"
   ],
   "id": "b0742ce6fcc05fa8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df2['Group1'].value_counts()",
   "id": "2ecdcb23cf197fce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "traits = ['Extraversion', 'Agreeableness', 'Conscientiousness', 'Neuroticism', 'Openness']\n",
    "# traits = ['Depressiveness', 'Loneliness', 'Self-esteem', 'Life Satisfaction', 'Health']\n",
    "# traits = [\"Communication Quality\", \"Relationship Satisfaction\", \"Conflict Management\"]\n",
    "\n",
    "stats = (\n",
    "    df2\n",
    "    .groupby('Group1')[traits]\n",
    "    .agg(['mean', 'std'])\n",
    ")\n",
    "print(stats)"
   ],
   "id": "6f3584b0d0f5a57a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
