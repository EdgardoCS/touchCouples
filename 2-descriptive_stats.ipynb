{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T13:50:43.349935Z",
     "start_time": "2026-02-18T13:50:43.343509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "a595510f0aaf52a7",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T13:50:43.439331Z",
     "start_time": "2026-02-18T13:50:43.366854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('source/FReDA3.csv')\n",
    "df2 = pd.read_csv('source/FReDA4.csv')"
   ],
   "id": "92d5ed993985fc6a",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T13:50:43.452763Z",
     "start_time": "2026-02-18T13:50:43.443413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "couples_satisfied = df[df[\"Group3\"] == \"Couple Satisfaction\"].copy()\n",
    "couples_deprived = df[df[\"Group3\"] == \"Couple Deprivation\"].copy()\n",
    "couples_saturated = df[df[\"Group3\"] == \"Couple Saturation\"].copy()\n",
    "couples_mixed = df[df[\"Group3\"] == \"Couple Mixed\"].copy()"
   ],
   "id": "2eec0bd034d43b0f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T13:50:43.487773Z",
     "start_time": "2026-02-18T13:50:43.459349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dfs = [couples_satisfied, couples_deprived, couples_saturated, couples_mixed]\n",
    "\n",
    "for df in dfs:\n",
    "\n",
    "    # 1. Identify columns (adjust names to match your exact CSV/DataFrame)\n",
    "    items = ['Frequency', 'Kiss Frequency', 'Hold Frequency', 'Hug Frequency',\n",
    "             'Desire', 'Kiss Desire', 'Hold Desire', 'Hug Desire']\n",
    "\n",
    "    # 2. Create 'Side A' (Anchor is the primary)\n",
    "    side_a = df[['Id'] + [f'Anchor {i}' for i in items] + [f'Partner {i}' for i in items]].copy()\n",
    "    side_a.columns = ['Couple_ID'] + [f'Self_{i}' for i in items] + [f'Partner_{i}' for i in items]\n",
    "\n",
    "    # 3. Create 'Side B' (Partner is the primary)\n",
    "    side_b = df[['Id'] + [f'Partner {i}' for i in items] + [f'Anchor {i}' for i in items]].copy()\n",
    "    side_b.columns = ['Couple_ID'] + [f'Self_{i}' for i in items] + [f'Partner_{i}' for i in items]\n",
    "\n",
    "    # 4. Merge\n",
    "    df_long = pd.concat([side_a, side_b], ignore_index=True)\n",
    "\n",
    "    # Select all Self and Partner columns to center\n",
    "    cols_to_center = [c for c in df_long.columns if 'Self_' in c or 'Partner_' in c]\n",
    "\n",
    "    # Calculate the mean for each couple ID\n",
    "    couple_means = df_long.groupby('Couple_ID')[cols_to_center].transform('mean')\n",
    "\n",
    "    # Center the data: (Actual Value - Couple Mean)\n",
    "    df_centered = df_long[cols_to_center] - couple_means\n",
    "\n",
    "    results = []\n",
    "    # Match Frequency items to their corresponding Desire items\n",
    "    categories = ['Frequency', 'Kiss Frequency', 'Hold Frequency', 'Hug Frequency']\n",
    "\n",
    "    for cat in categories:\n",
    "        freq_col = f'Self_{cat}'\n",
    "        # Mapping 'Frequency' to 'Desire'\n",
    "        desire_col = freq_col.replace('Frequency', 'Desire')\n",
    "\n",
    "        # Calculate Spearman Correlation on the centered data\n",
    "        r_val, p_val = stats.spearmanr(df_centered[freq_col], df_centered[desire_col])\n",
    "\n",
    "        results.append({\n",
    "            'Touch Type': cat.replace(' Frequency', '') or 'Overall',\n",
    "            'Spearman r (rm)': round(r_val, 3),\n",
    "            'p-value': '< .001' if p_val < .001 else round(p_val, 4)\n",
    "        })\n",
    "\n",
    "    # Final Table\n",
    "    table_output = pd.DataFrame(results)\n",
    "    print(table_output)"
   ],
   "id": "c3202867f0b0e3ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Touch Type  Spearman r (rm) p-value\n",
      "0  Frequency            1.000  < .001\n",
      "1       Kiss            0.991  < .001\n",
      "2       Hold            0.997  < .001\n",
      "3        Hug            0.995  < .001\n",
      "  Touch Type  Spearman r (rm) p-value\n",
      "0  Frequency            0.609  < .001\n",
      "1       Kiss            0.562  < .001\n",
      "2       Hold            0.672  < .001\n",
      "3        Hug            0.603  < .001\n",
      "  Touch Type  Spearman r (rm) p-value\n",
      "0  Frequency            0.586  < .001\n",
      "1       Kiss            0.433  < .001\n",
      "2       Hold            0.632  < .001\n",
      "3        Hug            0.650  < .001\n",
      "  Touch Type  Spearman r (rm) p-value\n",
      "0  Frequency            0.228  < .001\n",
      "1       Kiss            0.215  < .001\n",
      "2       Hold            0.330  < .001\n",
      "3        Hug            0.270  < .001\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T13:50:43.503783Z",
     "start_time": "2026-02-18T13:50:43.494270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "couples_satisfied = df2[df2[\"Group3\"] == \"Couple Satisfaction\"].copy()\n",
    "couples_deprived = df2[df2[\"Group3\"] == \"Couple Deprivation\"].copy()\n",
    "couples_saturated = df2[df2[\"Group3\"] == \"Couple Saturation\"].copy()\n",
    "couples_mixed = df2[df2[\"Group3\"] == \"Couple Mixed\"].copy()\n",
    "\n",
    "groups = ['Couple Deprivation', 'Couple Mixed', 'Couple Satisfaction', 'Couple Saturation']"
   ],
   "id": "e228ab326c55c715",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T13:50:43.511722Z",
     "start_time": "2026-02-18T13:50:43.508022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_interpretations(df):\n",
    "    baseline = 'Couple Satisfaction'\n",
    "    others = [g for g in df.index if g != baseline]\n",
    "\n",
    "    # Mapping for shorthand report\n",
    "    name_map = {\n",
    "        'Couple Deprivation': 'D',\n",
    "        'Couple Mixed': 'Mixed',\n",
    "        'Couple Saturation': 'Sat'\n",
    "    }\n",
    "\n",
    "    print(f\"{'Level':<10} | {'Comparison':<15} | {'Significance'}\")\n",
    "    print(\"-\" * 45)\n",
    "\n",
    "    for level in df.columns:\n",
    "        s_val = df.loc[baseline, level]\n",
    "\n",
    "        for other in others:\n",
    "            o_val = df.loc[other, level]\n",
    "\n",
    "            # Direction\n",
    "            symbol = \">\" if s_val > o_val else \"<\"\n",
    "\n",
    "            # Significance Check (Difference > 1.96)\n",
    "            diff = abs(s_val - o_val)\n",
    "            sig_status = \"Significant\" if diff > 1.96 else \"Not Significant\"\n",
    "\n",
    "            print(f\"{level:<10} | S {symbol} {name_map[other]:<10} | {sig_status}\")\n",
    "        print(\"-\" * 45)"
   ],
   "id": "1e49c95d44d0994c",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T13:56:56.259636Z",
     "start_time": "2026-02-18T13:56:56.237460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def report_kruskal_results(df, dv, group_col='Group3', baseline='Couple Satisfaction'):\n",
    "    # 1. Run Kruskal-Wallis\n",
    "    k_res = pg.kruskal(data=df, dv=dv, between=group_col)\n",
    "    h_val = k_res['H'].item()\n",
    "    p_val = k_res['p-unc'].item()\n",
    "\n",
    "    # 2. Effect Size: Eta-squared\n",
    "    n = df[dv].count()\n",
    "    k = df[group_col].nunique()\n",
    "    eta_sq = (h_val - k + 1) / (n - k)\n",
    "\n",
    "    # 3. Get Mean Ranks to determine direction\n",
    "    # We rank the DV across the whole dataset first\n",
    "    df_ranked = df.copy()\n",
    "    df_ranked['temp_rank'] = df[dv].rank()\n",
    "    mean_ranks = df_ranked.groupby(group_col)['temp_rank'].mean()\n",
    "\n",
    "    # 4. Post-hoc Dunn's test\n",
    "    posthoc = sp.posthoc_dunn(df, val_col=dv, group_col=group_col, p_adjust='bonferroni')\n",
    "\n",
    "    # 5. Build the comparison string (e.g., \"S > Sat\")\n",
    "    comparisons = []\n",
    "    name_map = {\n",
    "        'Couple Satisfaction': 'S',\n",
    "        'Couple Deprivation': 'Dep',\n",
    "        'Couple Saturation': 'Sat',\n",
    "        'Couple Mixed': 'Mixed'\n",
    "    }\n",
    "    baseline_ranks = mean_ranks[baseline]\n",
    "    short_base = name_map.get(baseline, 'S')\n",
    "    print(short_base)\n",
    "\n",
    "    # Loop through all groups in the index\n",
    "    for other_group in [g for g in mean_ranks.index if g != baseline]:\n",
    "        print(other_group)\n",
    "        p_comp = posthoc.loc[baseline, other_group]\n",
    "\n",
    "        # Only add to the string if the difference is statistically significant\n",
    "        if p_comp < 0.05:\n",
    "            symbol = \">\" if baseline_ranks > mean_ranks[other_group] else \"<\"\n",
    "            short_other = name_map.get(other_group, other_group)\n",
    "            comparisons.append(f\"{short_base} {symbol} {short_other}\")\n",
    "\n",
    "    # Format Significance\n",
    "    sig = \"***\" if p_val < .001 else \"**\" if p_val < .01 else \"*\" if p_val < .05 else \"ns\"\n",
    "\n",
    "    # Output Results\n",
    "    print(f\"Variable: {dv}\")\n",
    "    print(f\"Stats: η² = {eta_sq:.3f}, {sig}\")\n",
    "    print(f\"Post-hoc: {'; '.join(comparisons) if comparisons else 'No significant differences'}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# --- EXECUTION ---\n",
    "report_kruskal_results(df2, 'Education')"
   ],
   "id": "5be16c0d801be305",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\n",
      "Couple Deprivation\n",
      "Couple Mixed\n",
      "Couple Saturation\n",
      "Variable: Education\n",
      "Stats: η² = 0.003, ***\n",
      "Post-hoc: S > Sat\n",
      "------------------------------\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T13:51:52.026287Z",
     "start_time": "2026-02-18T13:51:52.007162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import scikit_posthocs as sp # You may need to: pip install scikit_posthocs\n",
    "import pingouin as pg\n",
    "\n",
    "dv = 'Education'\n",
    "group_col = 'Group3'\n",
    "\n",
    "# 1. Omnibus Test: Kruskal-Wallis\n",
    "kruskal_anova = pg.kruskal(data=df2, dv=dv, between=group_col)\n",
    "\n",
    "# 2. Effect Size: Eta-squared (H)\n",
    "n = df2[dv].count()\n",
    "k = df2[group_col].nunique()\n",
    "eta_sq_h = (kruskal_anova[\"H\"].item() - k + 1) / (n - k)\n",
    "\n",
    "print(\"--- Kruskal-Wallis Omnibus ---\")\n",
    "print(kruskal_anova)\n",
    "print(f'ETA-squared: {eta_sq_h:.4f}')\n",
    "\n",
    "# 3. Post-Hoc: Dunn's Test (The Standard for Kruskal-Wallis)\n",
    "# This compares groups (Satisfied vs Deprived, etc.) based on Mean Ranks\n",
    "posthoc = sp.posthoc_dunn(df2, val_col=dv, group_col=group_col, p_adjust='bonferroni')\n",
    "\n",
    "print(\"\\n--- Dunn's Post-Hoc (P-values with Bonferroni Correction) ---\")\n",
    "print(posthoc.round(4))"
   ],
   "id": "78902a064471b935",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Kruskal-Wallis Omnibus ---\n",
      "         Source  ddof1          H         p-unc\n",
      "Kruskal  Group3      3  45.665449  6.680727e-10\n",
      "ETA-squared: 0.0034\n",
      "\n",
      "--- Dunn's Post-Hoc (P-values with Bonferroni Correction) ---\n",
      "                     Couple Deprivation  Couple Mixed  Couple Satisfaction  \\\n",
      "Couple Deprivation               1.0000        0.2345               1.0000   \n",
      "Couple Mixed                     0.2345        1.0000               0.7862   \n",
      "Couple Satisfaction              1.0000        0.7862               1.0000   \n",
      "Couple Saturation                0.0000        0.0344               0.0000   \n",
      "\n",
      "                     Couple Saturation  \n",
      "Couple Deprivation              0.0000  \n",
      "Couple Mixed                    0.0344  \n",
      "Couple Satisfaction             0.0000  \n",
      "Couple Saturation               1.0000  \n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T14:30:37.910788Z",
     "start_time": "2026-02-18T14:30:37.901271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def report_binary_chi(df, dv, group_col='Group3', baseline='Couple Satisfaction'):\n",
    "    # 1. Create the crosstab (counts of 0s and 1s per group)\n",
    "    ct = pd.crosstab(df[dv], df[group_col])\n",
    "\n",
    "    # 2. Run Chi-Squared Omnibus\n",
    "    chi2, p_val, dof, expected = chi2_contingency(ct)\n",
    "\n",
    "    # 3. Effect Size: Cramer's V\n",
    "    n = ct.sum().sum()\n",
    "    r, k = ct.shape\n",
    "    v = np.sqrt(chi2 / (n * (min(r, k) - 1)))\n",
    "\n",
    "    # 4. Post-hoc: Adjusted Standardized Residuals\n",
    "    row_totals = ct.sum(axis=1).values\n",
    "    col_totals = ct.sum(axis=0).values\n",
    "    # Expected formula for residuals\n",
    "    v_adj = np.outer(row_totals, col_totals) * (1 - row_totals[:, None] / n) * (1 - col_totals / n) / n\n",
    "    adj_residuals = (ct.values - expected) / np.sqrt(v_adj)\n",
    "    res_df = pd.DataFrame(adj_residuals, index=ct.index, columns=ct.columns)\n",
    "\n",
    "    # 5. Build the comparison string (Comparing Baseline to others)\n",
    "    # We look at Category '1' (usually 'Yes') to determine direction\n",
    "    comparisons = []\n",
    "\n",
    "    # Mapping for your group abbreviations\n",
    "    name_map = {\n",
    "        'Couple Satisfaction': 'S',\n",
    "        'Couple Deprivation': 'Dep',\n",
    "        'Couple Saturation': 'Sat',\n",
    "        'Couple Mixed': 'Mix'\n",
    "    }\n",
    "\n",
    "    # Percentages for direction (e.g., % of 'Yes' in each group)\n",
    "    percentages = (ct / ct.sum()) * 100\n",
    "    base_pct = percentages.loc[1, baseline]\n",
    "\n",
    "    for other_group in [g for g in ct.columns if g != baseline]:\n",
    "        print(other_group)\n",
    "        # A cell is significant if |Z| > 1.96\n",
    "        # We check the Z-score for Category '1' (Yes)\n",
    "        z_score = res_df.loc[1, other_group]\n",
    "        print(z_score)\n",
    "\n",
    "        # If the groups are significantly different from each other\n",
    "        # print(name_map.get(other_group, other_group).replace('Couple ', '')[:3])\n",
    "        if abs(z_score) > 1.96:\n",
    "            other_pct = percentages.loc[1, other_group]\n",
    "            symbol = \">\" if base_pct > other_pct else \"<\"\n",
    "\n",
    "            short_base = name_map.get(baseline, 'S')\n",
    "            short_other = name_map.get(other_group)\n",
    "            comparisons.append(f\"{short_base} {symbol} {short_other}\")\n",
    "\n",
    "    # Format output\n",
    "    sig = \"***\" if p_val < .001 else \"**\" if p_val < .01 else \"*\" if p_val < .05 else \"ns\"\n",
    "\n",
    "    print(f\"Variable: {dv}\")\n",
    "    print(f\"Stats: η² (V) = {v:.3f}, {sig}\")\n",
    "    print(f\"Post-hoc: {'; '.join(comparisons) if comparisons else 'ns'}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# Run it\n",
    "report_binary_chi(df2, 'Cohabitation')"
   ],
   "id": "9d93030371fb7c3a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couple Deprivation\n",
      "7.0145503138225465\n",
      "Couple Mixed\n",
      "-0.6589033823530143\n",
      "Couple Saturation\n",
      "-2.768726815575294\n",
      "Variable: Cohabitation\n",
      "Stats: η² (V) = 0.061, ***\n",
      "Post-hoc: S < Dep; S > Sat\n",
      "------------------------------\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Source  ddof1          H         p-unc\n",
      "Kruskal  Group3      3  45.665449  6.680727e-10\n",
      "ETA-squared 0.00338802896202501\n",
      "--- (Standardized Residuals) ---\n",
      "Education             0.0   1.0   2.0   3.0   4.0   6.0   7.0   8.0\n",
      "Group3                                                             \n",
      "Couple Deprivation  -3.97  0.74 -0.82 -0.56 -0.01  0.47  0.65  1.28\n",
      "Couple Mixed        -1.25 -0.42  2.20  1.31  1.33 -1.79 -0.29 -0.22\n",
      "Couple Satisfaction  5.22 -1.73 -0.96 -1.53 -0.16  0.94 -0.10 -0.50\n",
      "Couple Saturation    2.73  1.84  2.90  4.16 -0.87 -2.03 -1.70 -2.99\n",
      "Level      | Comparison      | Significance\n",
      "---------------------------------------------\n",
      "0.0        | S > D          | Significant\n",
      "0.0        | S > Mixed      | Significant\n",
      "0.0        | S > Sat        | Significant\n",
      "---------------------------------------------\n",
      "1.0        | S < D          | Significant\n",
      "1.0        | S < Mixed      | Not Significant\n",
      "1.0        | S < Sat        | Significant\n",
      "---------------------------------------------\n",
      "2.0        | S < D          | Not Significant\n",
      "2.0        | S < Mixed      | Significant\n",
      "2.0        | S < Sat        | Significant\n",
      "---------------------------------------------\n",
      "3.0        | S < D          | Not Significant\n",
      "3.0        | S < Mixed      | Significant\n",
      "3.0        | S < Sat        | Significant\n",
      "---------------------------------------------\n",
      "4.0        | S < D          | Not Significant\n",
      "4.0        | S < Mixed      | Not Significant\n",
      "4.0        | S > Sat        | Not Significant\n",
      "---------------------------------------------\n",
      "6.0        | S > D          | Not Significant\n",
      "6.0        | S > Mixed      | Significant\n",
      "6.0        | S > Sat        | Significant\n",
      "---------------------------------------------\n",
      "7.0        | S < D          | Not Significant\n",
      "7.0        | S > Mixed      | Not Significant\n",
      "7.0        | S > Sat        | Not Significant\n",
      "---------------------------------------------\n",
      "8.0        | S < D          | Not Significant\n",
      "8.0        | S < Mixed      | Not Significant\n",
      "8.0        | S > Sat        | Significant\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 18,
   "source": [
    "dv = \"Married\"\n",
    "\n",
    "\n",
    "# drop = True\n",
    "#\n",
    "# count_base = couples_satisfied[dv].value_counts(dropna=drop)\n",
    "# count_d = couples_deprived[dv].value_counts(dropna=drop)\n",
    "# count_s = couples_saturated[dv].value_counts(dropna=drop)\n",
    "# count_m = couples_mixed[dv].value_counts(dropna=drop)\n",
    "#\n",
    "# summ = pd.DataFrame({\n",
    "#     'Satisfied': count_base,\n",
    "#     'Deprived': count_d,\n",
    "#     'Saturated': count_s,\n",
    "#     'Mixed': count_m,\n",
    "# })\n",
    "#\n",
    "# summ_cond = [\"Deprived\", \"Saturated\", \"Mixed\"]\n",
    "# for cond in summ_cond:\n",
    "#     print('Pairwise ---', cond)\n",
    "#     contingency = summ.filter(items=['Satisfied', cond])\n",
    "#     N = contingency.to_numpy().sum()\n",
    "#     res = chi2_contingency(contingency)\n",
    "#     chi_stat = res[0]\n",
    "#     print(f\"Dof:{res.dof}, Chi-square: {res.statistic}, p-value: {res.pvalue}\")\n",
    "#\n",
    "#     # Calculate Cramer's V\n",
    "#     r, k = contingency.shape\n",
    "#     result = np.sqrt(chi_stat / (N * (min(r-1, k-1))))\n",
    "#\n",
    "#     print(f\"Cramer's V: {result}\")"
   ],
   "id": "c3827a25de0a7205"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T13:50:43.643468Z",
     "start_time": "2026-02-18T13:50:43.629157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dv = 'Work Status'\n",
    "kruskal_anova = pg.kruskal(data=df2, dv=dv, between='Group3')\n",
    "n = df2[dv].count()\n",
    "k = df2[\"Group3\"].nunique()\n",
    "eta_sq_h = (kruskal_anova[\"H\"].item() - k + 1) / (n - k)\n",
    "\n",
    "print(kruskal_anova)\n",
    "print('ETA-squared', eta_sq_h)\n",
    "\n",
    "# 1. Run the Chi-square independence test\n",
    "expected, observed, stats = pg.chi2_independence(df2, x='Group3', y=dv)\n",
    "\n",
    "# 2. Calculate Standardized Residuals\n",
    "# These identify exactly which levels (0, 1, 2...) are different\n",
    "residuals = (observed - expected) / (expected**0.5)\n",
    "\n",
    "# 3. Print the residuals for the \"Satisfied\" row vs the others\n",
    "print(\"--- (Standardized Residuals) ---\")\n",
    "print(residuals.round(2))\n",
    "\n",
    "df_res = pd.DataFrame(residuals, index=groups)\n",
    "generate_interpretations(df_res)"
   ],
   "id": "f4cdf1473afdcf62",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Source  ddof1           H         p-unc\n",
      "Kruskal  Group3      3  135.454842  3.608807e-29\n",
      "ETA-squared 0.009853071605688202\n",
      "--- (Standardized Residuals) ---\n",
      "Work Status           0.0   1.0   2.0\n",
      "Group3                               \n",
      "Couple Deprivation   3.60  4.66 -3.87\n",
      "Couple Mixed         0.25 -0.43  0.13\n",
      "Couple Satisfaction -5.21 -5.22  4.80\n",
      "Couple Saturation   -0.42 -3.29  1.90\n",
      "Level      | Comparison      | Significance\n",
      "---------------------------------------------\n",
      "0.0        | S < D          | Significant\n",
      "0.0        | S < Mixed      | Significant\n",
      "0.0        | S < Sat        | Significant\n",
      "---------------------------------------------\n",
      "1.0        | S < D          | Significant\n",
      "1.0        | S < Mixed      | Significant\n",
      "1.0        | S < Sat        | Not Significant\n",
      "---------------------------------------------\n",
      "2.0        | S > D          | Significant\n",
      "2.0        | S > Mixed      | Significant\n",
      "2.0        | S > Sat        | Significant\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T13:50:43.663979Z",
     "start_time": "2026-02-18T13:50:43.650038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dv = 'Urbanization'\n",
    "kruskal_anova = pg.kruskal(data=df2, dv=dv, between='Group3')\n",
    "n = df2[dv].count()\n",
    "k = df2[\"Group3\"].nunique()\n",
    "eta_sq_h = (kruskal_anova[\"H\"].item() - k + 1) / (n - k)\n",
    "\n",
    "print(kruskal_anova)\n",
    "print('ETA-squared', eta_sq_h)\n",
    "\n",
    "# 1. Run the Chi-square independence test\n",
    "expected, observed, stats = pg.chi2_independence(df2, x='Group3', y=dv)\n",
    "\n",
    "# 2. Calculate Standardized Residuals\n",
    "# These identify exactly which levels (0, 1, 2...) are different\n",
    "residuals = (observed - expected) / (expected ** 0.5)\n",
    "\n",
    "# 3. Print the residuals for the \"Satisfied\" row vs the others\n",
    "print(\"--- \", dv, \"(Standardized Residuals) ---\")\n",
    "print(residuals.round(2))\n",
    "\n",
    "df_res = pd.DataFrame(residuals, index=groups)\n",
    "print(\"--- \", dv, \"(Interpretation) ---\")\n",
    "generate_interpretations(df_res)"
   ],
   "id": "8173529512015eb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Source  ddof1         H     p-unc\n",
      "Kruskal  Group3      3  25.16126  0.000014\n",
      "ETA-squared 0.001675709651394591\n",
      "---  Urbanization (Standardized Residuals) ---\n",
      "Urbanization          0.0   1.0   2.0\n",
      "Group3                               \n",
      "Couple Deprivation   1.27  1.22 -2.17\n",
      "Couple Mixed        -1.75 -1.37  2.66\n",
      "Couple Satisfaction -0.99 -0.52  1.24\n",
      "Couple Saturation   -0.36 -1.62  1.93\n",
      "---  Urbanization (Interpretation) ---\n",
      "Level      | Comparison      | Significance\n",
      "---------------------------------------------\n",
      "0.0        | S < D          | Significant\n",
      "0.0        | S > Mixed      | Not Significant\n",
      "0.0        | S < Sat        | Not Significant\n",
      "---------------------------------------------\n",
      "1.0        | S < D          | Not Significant\n",
      "1.0        | S > Mixed      | Not Significant\n",
      "1.0        | S > Sat        | Not Significant\n",
      "---------------------------------------------\n",
      "2.0        | S > D          | Significant\n",
      "2.0        | S < Mixed      | Not Significant\n",
      "2.0        | S < Sat        | Not Significant\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T13:50:43.696129Z",
     "start_time": "2026-02-18T13:50:43.680669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dv = 'Kids'\n",
    "kruskal_anova = pg.kruskal(data=df2, dv=dv, between='Group3')\n",
    "n = df2[dv].count()\n",
    "k = df2[\"Group3\"].nunique()\n",
    "eta_sq_h = (kruskal_anova[\"H\"].item() - k + 1) / (n - k)\n",
    "\n",
    "print(kruskal_anova)\n",
    "print('ETA-squared', eta_sq_h)\n",
    "\n",
    "# 1. Run the Chi-square independence test\n",
    "expected, observed, stats = pg.chi2_independence(df2, x='Group3', y=dv)\n",
    "\n",
    "# 2. Calculate Standardized Residuals\n",
    "# These identify exactly which levels (0, 1, 2...) are different\n",
    "residuals = (observed - expected) / (expected ** 0.5)\n",
    "\n",
    "# 3. Print the residuals for the \"Satisfied\" row vs the others\n",
    "print(\"--- \", dv, \"(Standardized Residuals) ---\")\n",
    "print(residuals.round(2))\n",
    "\n",
    "df_res = pd.DataFrame(residuals, index=groups)\n",
    "print(\"--- \", dv, \"(Interpretation) ---\")\n",
    "generate_interpretations(df_res)"
   ],
   "id": "902e2c513726f0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Source  ddof1           H          p-unc\n",
      "Kruskal  Group3      3  509.248086  4.725396e-110\n",
      "ETA-squared 0.03726248242713801\n",
      "---  Kids (Standardized Residuals) ---\n",
      "Kids                   0.0   1.0   2.0   3.0\n",
      "Group3                                      \n",
      "Couple Deprivation  -11.52  5.30  7.25  3.62\n",
      "Couple Mixed          0.66  1.38 -0.73 -2.23\n",
      "Couple Satisfaction  13.62 -7.52 -7.90 -3.53\n",
      "Couple Saturation     6.94 -1.94 -5.60 -1.98\n",
      "---  Kids (Interpretation) ---\n",
      "Level      | Comparison      | Significance\n",
      "---------------------------------------------\n",
      "0.0        | S > D          | Significant\n",
      "0.0        | S > Mixed      | Significant\n",
      "0.0        | S > Sat        | Significant\n",
      "---------------------------------------------\n",
      "1.0        | S < D          | Significant\n",
      "1.0        | S < Mixed      | Significant\n",
      "1.0        | S < Sat        | Significant\n",
      "---------------------------------------------\n",
      "2.0        | S < D          | Significant\n",
      "2.0        | S < Mixed      | Significant\n",
      "2.0        | S < Sat        | Significant\n",
      "---------------------------------------------\n",
      "3.0        | S < D          | Significant\n",
      "3.0        | S < Mixed      | Not Significant\n",
      "3.0        | S < Sat        | Not Significant\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T13:50:43.709196Z",
     "start_time": "2026-02-18T13:50:43.702457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "count_base = couples_satisfied['Region'].value_counts(dropna=False)\n",
    "count_d = couples_deprived['Region'].value_counts(dropna=False)\n",
    "count_s = couples_saturated['Region'].value_counts(dropna=False)\n",
    "count_m = couples_mixed['Region'].value_counts(dropna=False)\n",
    "\n",
    "contingency = pd.DataFrame({\n",
    "    'Satisfied': count_base,\n",
    "    'Deprived': count_d,\n",
    "    # 'Saturated': count_s,\n",
    "    # 'Mixed': count_m,\n",
    "})\n",
    "\n",
    "print(contingency)\n",
    "res = chi2_contingency(contingency)\n",
    "chi_stat = res[0]\n",
    "\n",
    "# Performing Cramer's V calculation\n",
    "# Size of the sample\n",
    "N = contingency.to_numpy().sum()\n",
    "# Minimum dimension\n",
    "minimum_dimension = (min(contingency.shape)-1)\n",
    "\n",
    "# Calculate Cramer's V\n",
    "r, k = contingency.shape\n",
    "result = np.sqrt(chi_stat / (N * (min(r-1, k-1))))\n",
    "\n",
    "chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "(expected < 5).sum()\n",
    "n_violations = (expected < 5).sum()\n",
    "total_cells = expected.size\n",
    "\n",
    "print(f\"Cells with expected count < 5: {n_violations}/{total_cells}\")\n",
    "print(f\"Percentage: {100 * n_violations / total_cells:.1f}%\")\n",
    "print(f\"Cramer's V: {result}\")\n",
    "print(f\"Dof:{res.dof}, Chi-square: {res.statistic}, p-value: {res.pvalue}\")"
   ],
   "id": "1d7983c5033a92c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Satisfied  Deprived\n",
      "Region                     \n",
      "1.0          3210      6858\n",
      "0.0           533      1273\n",
      "NaN            99       211\n",
      "Cells with expected count < 5: 0/6\n",
      "Percentage: 0.0%\n",
      "Cramer's V: 0.01814015824374786\n",
      "Dof:2, Chi-square: 4.009332116062472, p-value: 0.13470527192907278\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T13:50:43.739431Z",
     "start_time": "2026-02-18T13:50:43.724422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dv = 'Married'\n",
    "kruskal_anova = pg.kruskal(data=df2, dv=dv, between='Group3')\n",
    "n = df2[dv].count()\n",
    "k = df2[\"Group3\"].nunique()\n",
    "eta_sq_h = (kruskal_anova[\"H\"].item() - k + 1) / (n - k)\n",
    "\n",
    "print(kruskal_anova)\n",
    "print('ETA-squared', eta_sq_h)\n",
    "\n",
    "# 1. Run the Chi-square independence test\n",
    "expected, observed, stats = pg.chi2_independence(df2, x='Group3', y=dv)\n",
    "\n",
    "# 2. Calculate Standardized Residuals\n",
    "# These identify exactly which levels (0, 1, 2...) are different\n",
    "residuals = (observed - expected) / (expected ** 0.5)\n",
    "\n",
    "# 3. Print the residuals for the \"Satisfied\" row vs the others\n",
    "print(\"--- \", dv, \"(Standardized Residuals) ---\")\n",
    "print(residuals.round(2))\n",
    "\n",
    "df_res = pd.DataFrame(residuals, index=groups)\n",
    "print(\"--- \", dv, \"(Interpretation) ---\")\n",
    "generate_interpretations(df_res)"
   ],
   "id": "da8ec0e1d5556dbe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Source  ddof1           H         p-unc\n",
      "Kruskal  Group3      3  187.920791  1.716877e-40\n",
      "ETA-squared 0.013603118338376687\n",
      "---  Married (Standardized Residuals) ---\n",
      "Married               0.0   1.0\n",
      "Group3                         \n",
      "Couple Deprivation  -6.61  4.90\n",
      "Couple Mixed         0.82 -0.61\n",
      "Couple Satisfaction  7.12 -5.28\n",
      "Couple Saturation    5.12 -3.79\n",
      "---  Married (Interpretation) ---\n",
      "Level      | Comparison      | Significance\n",
      "---------------------------------------------\n",
      "0.0        | S > D          | Significant\n",
      "0.0        | S > Mixed      | Significant\n",
      "0.0        | S > Sat        | Significant\n",
      "---------------------------------------------\n",
      "1.0        | S < D          | Significant\n",
      "1.0        | S < Mixed      | Significant\n",
      "1.0        | S < Sat        | Not Significant\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T13:50:43.759707Z",
     "start_time": "2026-02-18T13:50:43.745435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dv = 'Cohabitation'\n",
    "kruskal_anova = pg.kruskal(data=df2, dv=dv, between='Group3')\n",
    "n = df2[dv].count()\n",
    "k = df2[\"Group3\"].nunique()\n",
    "eta_sq_h = (kruskal_anova[\"H\"].item() - k + 1) / (n - k)\n",
    "\n",
    "print(kruskal_anova)\n",
    "print('ETA-squared', eta_sq_h)\n",
    "\n",
    "# 1. Run the Chi-square independence test\n",
    "expected, observed, stats = pg.chi2_independence(df2, x='Group3', y=dv)\n",
    "\n",
    "# 2. Calculate Standardized Residuals\n",
    "# These identify exactly which levels (0, 1, 2...) are different\n",
    "residuals = (observed - expected) / (expected ** 0.5)\n",
    "\n",
    "# 3. Print the residuals for the \"Satisfied\" row vs the others\n",
    "print(\"--- \", dv, \"(Standardized Residuals) ---\")\n",
    "print(residuals.round(2))\n",
    "\n",
    "df_res = pd.DataFrame(residuals, index=groups)\n",
    "print(\"--- \", dv, \"(Interpretation) ---\")\n",
    "generate_interpretations(df_res)"
   ],
   "id": "3b29b02bfff420d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Source  ddof1          H         p-unc\n",
      "Kruskal  Group3      3  51.342131  4.136180e-11\n",
      "ETA-squared 0.003555614214657242\n",
      "---  Cohabitation (Standardized Residuals) ---\n",
      "Cohabitation            0     1\n",
      "Group3                         \n",
      "Couple Deprivation  -4.17  1.26\n",
      "Couple Mixed         0.62 -0.19\n",
      "Couple Satisfaction  4.75 -1.44\n",
      "Couple Saturation    2.58 -0.78\n",
      "---  Cohabitation (Interpretation) ---\n",
      "Level      | Comparison      | Significance\n",
      "---------------------------------------------\n",
      "0          | S > D          | Significant\n",
      "0          | S > Mixed      | Significant\n",
      "0          | S > Sat        | Significant\n",
      "---------------------------------------------\n",
      "1          | S < D          | Significant\n",
      "1          | S < Mixed      | Not Significant\n",
      "1          | S < Sat        | Not Significant\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T13:50:43.772419Z",
     "start_time": "2026-02-18T13:50:43.765136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "drop = True\n",
    "count_base = couples_satisfied['Sex'].value_counts(dropna=drop)\n",
    "count_d = couples_deprived['Sex'].value_counts(dropna=drop)\n",
    "count_s = couples_saturated['Sex'].value_counts(dropna=drop)\n",
    "count_m = couples_mixed['Sex'].value_counts(dropna=drop)\n",
    "\n",
    "contingency = pd.DataFrame({\n",
    "    'Satisfied': count_base,\n",
    "    # 'Deprived': count_d,\n",
    "    # 'Saturated': count_s,\n",
    "    'Mixed': count_m,\n",
    "})\n",
    "\n",
    "print(contingency)\n",
    "res = chi2_contingency(contingency)\n",
    "chi_stat = res[0]\n",
    "\n",
    "# Performing Cramer's V calculation\n",
    "# Size of the sample\n",
    "N = contingency.to_numpy().sum()\n",
    "# Minimum dimension\n",
    "minimum_dimension = (min(contingency.shape)-1)\n",
    "\n",
    "# Calculate Cramer's V\n",
    "r, k = contingency.shape\n",
    "result = np.sqrt(chi_stat / (N * (min(r-1, k-1))))\n",
    "\n",
    "chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "(expected < 5).sum()\n",
    "n_violations = (expected < 5).sum()\n",
    "total_cells = expected.size\n",
    "\n",
    "print(f\"Cells with expected count < 5: {n_violations}/{total_cells}\")\n",
    "print(f\"Percentage: {100 * n_violations / total_cells:.1f}%\")\n",
    "print(f\"Cramer's V: {result}\")\n",
    "print(f\"Dof:{res.dof}, Chi-square: {res.statistic}, p-value: {res.pvalue}\")"
   ],
   "id": "878a69158a268fad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Satisfied  Mixed\n",
      "Sex                  \n",
      "0.0       1916    331\n",
      "1.0       1918    328\n",
      "Cells with expected count < 5: 0/4\n",
      "Percentage: 0.0%\n",
      "Cramer's V: 0.0011659593118967008\n",
      "Dof:1, Chi-square: 0.006108058798674834, p-value: 0.9377054963235312\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T13:50:43.797967Z",
     "start_time": "2026-02-18T13:50:43.784417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "dv = 'Relationship Sex'\n",
    "kruskal_anova = pg.kruskal(data=df2, dv=dv, between='Group3')\n",
    "n = df2[dv].count()\n",
    "k = df2[\"Group3\"].nunique()\n",
    "eta_sq_h = (kruskal_anova[\"H\"].item() - k + 1) / (n - k)\n",
    "\n",
    "print(kruskal_anova)\n",
    "print('ETA-squared', eta_sq_h)\n",
    "\n",
    "# 1. Run the Chi-square independence test\n",
    "expected, observed, stats = pg.chi2_independence(df2, x='Group3', y=dv)\n",
    "\n",
    "# 2. Calculate Standardized Residuals\n",
    "# These identify exactly which levels (0, 1, 2...) are different\n",
    "residuals = (observed - expected) / (expected ** 0.5)\n",
    "\n",
    "# 3. Print the residuals for the \"Satisfied\" row vs the others\n",
    "print(\"--- \", dv, \"(Standardized Residuals) ---\")\n",
    "print(residuals.round(2))\n",
    "\n",
    "df_res = pd.DataFrame(residuals, index=groups)\n",
    "print(\"--- \", dv, \"(Interpretation) ---\")\n",
    "generate_interpretations(df_res)"
   ],
   "id": "9b19d57528963aad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Source  ddof1         H     p-unc\n",
      "Kruskal  Group3      3  3.461688  0.325765\n",
      "ETA-squared 3.395766311696073e-05\n",
      "---  Relationship Sex (Standardized Residuals) ---\n",
      "Relationship Sex        0     1\n",
      "Group3                         \n",
      "Couple Deprivation   0.12 -0.65\n",
      "Couple Mixed         0.01 -0.05\n",
      "Couple Satisfaction -0.04  0.23\n",
      "Couple Saturation   -0.32  1.69\n",
      "---  Relationship Sex (Interpretation) ---\n",
      "Level      | Comparison      | Significance\n",
      "---------------------------------------------\n",
      "0          | S < D          | Not Significant\n",
      "0          | S < Mixed      | Not Significant\n",
      "0          | S > Sat        | Not Significant\n",
      "---------------------------------------------\n",
      "1          | S > D          | Not Significant\n",
      "1          | S > Mixed      | Not Significant\n",
      "1          | S < Sat        | Not Significant\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T14:27:33.534799Z",
     "start_time": "2026-02-18T14:27:33.499095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dv = 'Age'\n",
    "anova = pg.anova(data=df2, dv=dv, between='Group3')\n",
    "\n",
    "print(\"---------- \", dv, \"ANOVA ----------\")\n",
    "print(anova)\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "summ_cond = [\"Couple Deprivation\", \"Couple Saturation\", \"Couple Mixed\"]\n",
    "for cond in summ_cond:\n",
    "    ttest = pg.ttest(\n",
    "        x=df2[df2['Group3'] == 'Couple Satisfaction']['Age'],\n",
    "        y=df2[df2['Group3'] == cond]['Age'],\n",
    "    )\n",
    "    print(\"---------- \", cond, \"ttest ----------\")\n",
    "    print(ttest)\n",
    "\n",
    "# Pairwise T-tests with Bonferroni correction to avoid false positives\n",
    "posthocs = pg.pairwise_tests(data=df2, dv='Age', between='Group3', padjust='bonf')\n",
    "print(posthocs)\n",
    "\n",
    "# expected, observed, stats = pg.chi2_independence(df2, x='Group3', y=dv)\n",
    "#\n",
    "# # 2. Calculate Standardized Residuals\n",
    "# # These identify exactly which levels (0, 1, 2...) are different\n",
    "# residuals = (observed - expected) / (expected ** 0.5)\n",
    "#\n",
    "# # 3. Print the residuals for the \"Satisfied\" row vs the others\n",
    "# print(\"--- \", dv, \"(Standardized Residuals) ---\")\n",
    "# print(residuals.round(2))\n",
    "# #\n",
    "# # df_res = pd.DataFrame(residuals, index=groups)\n",
    "# # print(\"--- \", dv, \"(Interpretation) ---\")\n",
    "# # generate_interpretations(df_res)"
   ],
   "id": "540f4e4a3ca1edfa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------  Age ANOVA ----------\n",
      "   Source  ddof1  ddof2          F         p-unc       np2\n",
      "0  Group3      3  13596  42.300862  3.359902e-27  0.009248\n",
      "--------------------------------\n",
      "----------  Couple Deprivation ttest ----------\n",
      "               T          dof alternative         p-val           CI95%  \\\n",
      "T-test -8.206534  6812.984045   two-sided  2.699149e-16  [-1.74, -1.07]   \n",
      "\n",
      "         cohen-d       BF10  power  \n",
      "T-test  0.166255  8.049e+12    1.0  \n",
      "----------  Couple Saturation ttest ----------\n",
      "               T          dof alternative     p-val         CI95%   cohen-d  \\\n",
      "T-test  3.855382  1084.774546   two-sided  0.000122  [0.67, 2.07]  0.151667   \n",
      "\n",
      "          BF10     power  \n",
      "T-test  71.511  0.967927  \n",
      "----------  Couple Mixed ttest ----------\n",
      "               T         dof alternative     p-val          CI95%   cohen-d  \\\n",
      "T-test -1.435701  936.433938   two-sided  0.151421  [-1.23, 0.19]  0.057744   \n",
      "\n",
      "         BF10     power  \n",
      "T-test  0.132  0.278086  \n",
      "  Contrast                    A                    B  Paired  Parametric  \\\n",
      "0   Group3   Couple Deprivation         Couple Mixed   False        True   \n",
      "1   Group3   Couple Deprivation  Couple Satisfaction   False        True   \n",
      "2   Group3   Couple Deprivation    Couple Saturation   False        True   \n",
      "3   Group3         Couple Mixed  Couple Satisfaction   False        True   \n",
      "4   Group3         Couple Mixed    Couple Saturation   False        True   \n",
      "5   Group3  Couple Satisfaction    Couple Saturation   False        True   \n",
      "\n",
      "          T          dof alternative         p-unc        p-corr p-adjust  \\\n",
      "0  2.595034   758.836925   two-sided  9.640841e-03  5.784504e-02     bonf   \n",
      "1  8.206534  6812.984045   two-sided  2.699149e-16  1.619489e-15     bonf   \n",
      "2  8.260760   873.878154   two-sided  5.332573e-16  3.199544e-15     bonf   \n",
      "3  1.435701   936.433938   two-sided  1.514214e-01  9.085286e-01     bonf   \n",
      "4  4.083011  1403.376152   two-sided  4.696514e-05  2.817908e-04     bonf   \n",
      "5  3.855382  1084.774546   two-sided  1.223406e-04  7.340437e-04     bonf   \n",
      "\n",
      "        BF10    hedges  \n",
      "0       1.29  0.108394  \n",
      "1  8.049e+12  0.166245  \n",
      "2   2.08e+13  0.337359  \n",
      "3      0.132  0.057734  \n",
      "4    218.614  0.216674  \n",
      "5     71.511  0.151642  \n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T13:50:43.870464Z",
     "start_time": "2026-02-18T13:50:43.865475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "count_base = couples_satisfied['Age']\n",
    "count_d = couples_deprived['Age']\n",
    "count_s = couples_saturated['Age']\n",
    "count_m = couples_mixed['Age']\n",
    "\n",
    "rvs1 = count_base\n",
    "rvs2 = count_m\n",
    "\n",
    "t, p = ttest_ind(rvs1, rvs2, equal_var=False)\n",
    "m1, sd1, n1 = rvs1.mean(), rvs1.std(ddof=1), len(rvs1)\n",
    "m2, sd2, n2 = rvs2.mean(), rvs2.std(ddof=1), len(rvs2)\n",
    "s1, s2 = sd1 ** 2, sd2 ** 2\n",
    "\n",
    "df = (s1 / n1 + s2 / n2) ** 2 / (\n",
    "        (s1 / n1) ** 2 / (n1 - 1) + (s2 / n2) ** 2 / (n2 - 1)\n",
    ")\n",
    "sd_pooled = np.sqrt((s1 + s2) / 2)\n",
    "d = (m1 - m2) / sd_pooled\n",
    "\n",
    "\n",
    "report = (\n",
    "    # f\"An independent-samples Welch’s t-test showed that \"\n",
    "    # f\"Group A (M = {m1:.2f}, SD = {sd1:.2f}) scored higher than \"\n",
    "    # f\"Group B (M = {m2:.2f}, SD = {sd2:.2f}), \"\n",
    "    f\"t({df:.2f}) = {t:.2f}, p {p}, d = {d:.2f}.\"\n",
    ")\n",
    "print(report)"
   ],
   "id": "433d4a03c61fb759",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t(936.43) = -1.44, p 0.15142143056957713, d = -0.06.\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T13:50:43.894895Z",
     "start_time": "2026-02-18T13:50:43.888379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# rename_map = {\n",
    "#     'SubGroup1': 'Satisfied',\n",
    "#     'SubGroup2': 'Deprived_Me',\n",
    "#     'SubGroup3': 'Deprived_Couples',\n",
    "#     'SubGroup7': 'Deprived_Partner',\n",
    "#     'SubGroup5': 'Saturated_Me',\n",
    "#     'SubGroup6': 'Saturated_Couples',\n",
    "#     'SubGroup8': 'Saturated_Partner',\n",
    "#     'SubGroup4': 'Mixed_Couples',\n",
    "#     'SubGroup9': 'Mixed_Couples'\n",
    "# }\n",
    "\n",
    "# rename_map = {\n",
    "#     'SubGroup1': 'Satisfied',\n",
    "#     'SubGroup2': 'Deprived_One',\n",
    "#     'SubGroup3': 'Deprived_Couples',\n",
    "#     'SubGroup7': 'Deprived_One',\n",
    "#     'SubGroup5': 'Saturated_One',\n",
    "#     'SubGroup6': 'Saturated_Couples',\n",
    "#     'SubGroup8': 'Saturated_One',\n",
    "#     'SubGroup4': 'Mixed_Couples',\n",
    "#     'SubGroup9': 'Mixed_Couples'\n",
    "# }\n",
    "\n",
    "# df2['Group1'] = df2['Group1'].replace(rename_map)\n",
    "# Satisfied\n",
    "df2.loc[df2['Group3'] == 'Couple Satisfaction', 'Group4'] = 'Couple Satisfaction'\n",
    "\n",
    "# Deprived groups\n",
    "# df2.loc[df2['Group3'] == 'Couple Deprivation', 'Group4'] = 'Couple Deprivation'\n",
    "df2.loc[df2['Group2'] == 'One-sided Deprivation', 'Group4'] = 'Deprived_One'\n",
    "df2.loc[df2['Group1'] == 'SubGroup3', 'Group4'] = 'Deprived_Both'\n",
    "\n",
    "# Saturated groups\n",
    "# df2.loc[df2['Group3'] == 'Couple Saturation', 'Group4'] = 'Couple Saturation'\n",
    "df2.loc[df2['Group2'] == 'One-sided Saturation', 'Group4'] = 'Saturated_One'\n",
    "df2.loc[df2['Group1'] == 'SubGroup6', 'Group4'] = 'Saturated_Both'\n",
    "\n",
    "df2.loc[df2['Group3'] == 'Couple Mixed', 'Group4'] = 'Couple Mixed'"
   ],
   "id": "b0742ce6fcc05fa8",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T13:50:43.907516Z",
     "start_time": "2026-02-18T13:50:43.902706Z"
    }
   },
   "cell_type": "code",
   "source": "df2['Group4'].value_counts()",
   "id": "2ecdcb23cf197fce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Group4\n",
       "Deprived_One           4940\n",
       "Couple Satisfaction    3842\n",
       "Deprived_Both          3402\n",
       "Saturated_One           666\n",
       "Couple Mixed            660\n",
       "Saturated_Both           90\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T13:50:44.005750Z",
     "start_time": "2026-02-18T13:50:43.934908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "groups = [\n",
    "    'Deprived_One',\n",
    "    'Couple Satisfaction',\n",
    "    'Deprived_Both',\n",
    "    'Saturated_One',\n",
    "    'Couple Mixed',\n",
    "    'Saturated_Both'\n",
    "]\n",
    "\n",
    "traits = ['Neuroticism', 'Extraversion', 'Agreeableness', 'Conscientiousness', 'Openness',\n",
    "          'Depressiveness', 'Loneliness', 'Self-esteem', 'Life Satisfaction', 'Health',\n",
    "          \"Communication Quality\", \"Relationship Satisfaction\", \"Conflict Management\"]\n",
    "\n",
    "stats = (\n",
    "    df2\n",
    "    .groupby('Group4')[traits]\n",
    "    .agg(['mean', 'std'])\n",
    ")\n",
    "# print(stats)\n",
    "\n",
    "for group in groups:\n",
    "    # 1. Clean up the columns (optional, but makes things easier)\n",
    "    df_tidy = stats.stack(level=0)  # Moves Neuroticism/Extraversion to the rows\n",
    "\n",
    "    # 2. Select a specific group to display (e.g., 'Couple Satisfaction')\n",
    "    satisfied_group = df_tidy.loc[group].copy()\n",
    "\n",
    "    # 3. Rename columns for the final look\n",
    "    satisfied_group.columns = ['Score', 'SD']\n",
    "\n",
    "    # 4. Round to 2 decimal places as in your example\n",
    "    satisfied_group = satisfied_group.round(2)\n",
    "    print(\"--------------\", group, \"--------------\")\n",
    "    print(satisfied_group)"
   ],
   "id": "6f3584b0d0f5a57a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Deprived_One --------------\n",
      "                           Score    SD\n",
      "Agreeableness              10.97  1.95\n",
      "Communication Quality      21.87  3.37\n",
      "Conflict Management        23.40  3.11\n",
      "Conscientiousness          10.97  2.13\n",
      "Depressiveness              5.06  1.61\n",
      "Extraversion                9.30  2.03\n",
      "Health                      3.77  0.79\n",
      "Life Satisfaction           7.86  1.57\n",
      "Loneliness                  1.85  1.02\n",
      "Neuroticism                 7.99  2.41\n",
      "Openness                    9.93  2.23\n",
      "Relationship Satisfaction   8.67  1.54\n",
      "Self-esteem                11.44  2.43\n",
      "-------------- Couple Satisfaction --------------\n",
      "                           Score    SD\n",
      "Agreeableness              11.10  1.95\n",
      "Communication Quality      23.44  3.05\n",
      "Conflict Management        24.35  2.91\n",
      "Conscientiousness          11.06  2.11\n",
      "Depressiveness              4.82  1.54\n",
      "Extraversion                9.42  2.05\n",
      "Health                      3.91  0.77\n",
      "Life Satisfaction           8.20  1.51\n",
      "Loneliness                  1.61  0.89\n",
      "Neuroticism                 7.62  2.32\n",
      "Openness                   10.10  2.23\n",
      "Relationship Satisfaction   9.31  1.15\n",
      "Self-esteem                11.93  2.28\n",
      "-------------- Deprived_Both --------------\n",
      "                           Score    SD\n",
      "Agreeableness              10.77  2.00\n",
      "Communication Quality      20.72  3.43\n",
      "Conflict Management        22.71  3.13\n",
      "Conscientiousness          10.93  2.14\n",
      "Depressiveness              5.25  1.63\n",
      "Extraversion                9.21  2.02\n",
      "Health                      3.68  0.80\n",
      "Life Satisfaction           7.60  1.61\n",
      "Loneliness                  2.06  1.10\n",
      "Neuroticism                 8.28  2.38\n",
      "Openness                    9.74  2.25\n",
      "Relationship Satisfaction   8.15  1.63\n",
      "Self-esteem                11.10  2.48\n",
      "-------------- Saturated_One --------------\n",
      "                           Score    SD\n",
      "Agreeableness              11.05  1.89\n",
      "Communication Quality      22.86  3.29\n",
      "Conflict Management        23.63  3.20\n",
      "Conscientiousness          11.02  2.12\n",
      "Depressiveness              5.14  1.67\n",
      "Extraversion                9.46  2.04\n",
      "Health                      3.85  0.81\n",
      "Life Satisfaction           7.90  1.66\n",
      "Loneliness                  1.80  1.01\n",
      "Neuroticism                 8.00  2.36\n",
      "Openness                   10.05  2.20\n",
      "Relationship Satisfaction   8.95  1.44\n",
      "Self-esteem                11.40  2.54\n",
      "-------------- Couple Mixed --------------\n",
      "                           Score    SD\n",
      "Agreeableness              10.80  2.20\n",
      "Communication Quality      21.17  3.76\n",
      "Conflict Management        22.72  3.35\n",
      "Conscientiousness          10.86  2.24\n",
      "Depressiveness              5.45  1.78\n",
      "Extraversion                9.25  2.10\n",
      "Health                      3.65  0.86\n",
      "Life Satisfaction           7.49  1.85\n",
      "Loneliness                  2.18  1.20\n",
      "Neuroticism                 8.35  2.55\n",
      "Openness                    9.90  2.32\n",
      "Relationship Satisfaction   8.07  2.03\n",
      "Self-esteem                10.97  2.61\n",
      "-------------- Saturated_Both --------------\n",
      "                           Score    SD\n",
      "Agreeableness              10.52  2.21\n",
      "Communication Quality      22.95  3.29\n",
      "Conflict Management        23.86  2.62\n",
      "Conscientiousness          11.57  2.27\n",
      "Depressiveness              4.86  1.43\n",
      "Extraversion               10.06  2.04\n",
      "Health                      3.71  0.77\n",
      "Life Satisfaction           8.18  1.52\n",
      "Loneliness                  1.72  1.10\n",
      "Neuroticism                 7.79  2.58\n",
      "Openness                    9.54  2.04\n",
      "Relationship Satisfaction   8.90  1.41\n",
      "Self-esteem                11.56  2.64\n"
     ]
    }
   ],
   "execution_count": 31
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
